{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports \"\"\"\n",
    "import json\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Database Schema\n",
    "\n",
    "## What data do we need\n",
    "\n",
    "Starting from the top, what information should we display to users?\n",
    "\n",
    "example return field in csv format (use tsv since a few course/dept names have commas)\n",
    "\n",
    "Example: user selects inst=UCSC, course=MATH19A\n",
    "`San Diego Miramar College, MATH 150, Calculus with Analytic Geometry I, 4 units`\n",
    "\n",
    "Example: user selects inst=UCSD, course=CHEM6B\n",
    "\n",
    "`San Diego Miramar College, CHEM 200, General Chemistry I - Lecture, 3 units`\n",
    "\n",
    "`and`\n",
    "\n",
    "`San Diego Miramar College, CHEM 201, General Chemistry II - Lecture, 3 units`\n",
    "\n",
    "\n",
    "Required data:\n",
    "- sending institution (e.g. San Diego Miramar College)\n",
    "- course prefix (e.g. CHEM)\n",
    "- course number (e.g. 201)\n",
    "- course name (e.g. General Chemistry II - Lecture)\n",
    "- unit count (e.g 3 units)\n",
    "- course ID (some string of numbers, makes mappings easy to deal with)\n",
    "\n",
    "\n",
    "## The schema\n",
    "\n",
    "Table 1: course glossary\n",
    "\n",
    "fields:\n",
    "- id (int, primary key)  // course id\n",
    "- inst (string)  // community college or univ\n",
    "- prefix (string)  // course prefix (e.g. CHEM)\n",
    "- course number (int) \n",
    "- course name (string)\n",
    "- min units (int)  // if min units and max units are the same, display 1\n",
    "- max units (int)\n",
    "\n",
    "Table 2: articulations\n",
    "fields:\n",
    "- id: (int, primary key)\n",
    "- inst (uni) (string)\n",
    "- agreements (json string)\n",
    "\n",
    "## The JSON string\n",
    "\n",
    "tbd, working on that rn\n",
    "\n",
    "## The query flow\n",
    "\n",
    "- user enters site\n",
    "- user picks university -> get list of all courses at university for dropdown\n",
    "    - sends request to backend\n",
    "    - backend uses user input to send query to db\n",
    "        -  `FROM glossary SELECT * WHERE inst IS {whatever the user picked}`\n",
    "    - backend converts results into json w/ id: {prefix, num, name, min units, max units}  // use for formatting dropdown\n",
    "    - backend returns json\n",
    "- user picks course from list -> get list of all articulated courses from id\n",
    "    - sends request to backend\n",
    "    - backend uses user input to send query to db\n",
    "        - `FROM articulations SELECT agreements WHERE id IS {id of course user picked}`\n",
    "        - returns 1 json string with all articulations\n",
    "    - backend aggregates all json string'd course IDs into list, queries course data\n",
    "        - `FROM glossary SELECT * WHERE id IS {ids in list}`\n",
    "    - backend converts results into json w/ id: {inst, prefix, num, name, min units, max units}  // actual displayed data\n",
    "    - backend returns both jsons (articulation string w/ IDs and the cc glossary)\n",
    "- both jsons formatted into cells on frontend\n",
    "- user gets results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define functions for generating an in-memory glossary of every course in an AllPrefixes agreement page \"\"\"\n",
    "\n",
    "def get_query(cc_id: int, uni_id: int) -> list[dict]:\n",
    "    with open(f\"./data/{uni_id}/{cc_id}to{uni_id}.json\", \"r\") as fp:\n",
    "        out = json.load(fp)\n",
    "    return out\n",
    "    \n",
    "\n",
    "def update_courses(courselist: list[dict], glossary: dict, inst: int) -> None:\n",
    "    for course in courselist:\n",
    "        if not all((course[\"prefix\"],\n",
    "                    course[\"courseNumber\"],\n",
    "                    course[\"courseTitle\"],\n",
    "                    course[\"minUnits\"],\n",
    "                    course[\"maxUnits\"],\n",
    "                    course[\"begin\"])):\n",
    "            continue\n",
    "            \n",
    "        course_id: int = course[\"courseIdentifierParentId\"]\n",
    "        \n",
    "        if course_id not in glossary:            \n",
    "            glossary[course_id] = {\n",
    "                \"course_id\": course_id,\n",
    "                \"inst_id\": int(inst),\n",
    "                \"course_code\": f\"{course[\"prefix\"]} {course[\"courseNumber\"]}\",\n",
    "                \"course_name\": course[\"courseTitle\"],\n",
    "                \"min_units\": int(course[\"minUnits\"]),\n",
    "                \"max_units\": int(course[\"maxUnits\"]),\n",
    "                \"begin\": course[\"begin\"]\n",
    "            }\n",
    "\n",
    "\n",
    "def create_course_glossary(cc: int, uni: int) -> pl.DataFrame:\n",
    "    # create output glossary\n",
    "    course_glossary = dict()\n",
    "    \n",
    "    with open(f\"./data/{uni}/{cc}to{uni}.json\", \"r\") as fp:\n",
    "        articulations = json.load(fp)\n",
    "    \n",
    "    # populate query\n",
    "    for dept in articulations:\n",
    "        articulationList = dept[\"articulations\"] if \"articulations\" in dept else [dept[\"articulation\"]]\n",
    "        \n",
    "        \n",
    "        for articulation in articulationList:\n",
    "            if \"requirement\" in articulation and \"course\" not in articulation and \"series\" not in articulation:\n",
    "                continue\n",
    "            # handle university courses\n",
    "            uni_courses: list[dict] = [articulation[\"course\"]] if \"course\" in articulation else articulation[\"series\"][\"courses\"]\n",
    "                \n",
    "            update_courses(courselist=uni_courses, glossary=course_glossary, inst=uni)\n",
    "                \n",
    "            # handle cc courses\n",
    "            agreements: dict | None = articulation[\"sendingArticulation\"]\n",
    "            if isinstance(agreements, dict):\n",
    "                for agreement in agreements[\"items\"]:\n",
    "                    if \"items\" in agreement:\n",
    "                        update_courses(courselist=agreement[\"items\"], glossary=course_glossary, inst=cc)\n",
    "                    else:\n",
    "                        with open(\"./data/known_errors.tsv\", \"a\") as fp:\n",
    "                            fp.write(f\"{cc}\\t{uni}\\tKnown issue with parsing 'Select 1 course from following' as OR block\")\n",
    "        \n",
    "    return pl.DataFrame(pd.DataFrame(course_glossary.values(), index=course_glossary.keys()))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Articulations are expected to have duplicates\n",
    "course_id : agreement json -> for 1 uni:cc pairing, therefore many of these should exist in the final table\n",
    "queries will look like: SELECT articulation FROM articulations WHERE 'course_id' == [number]\n",
    "which will return a slice\n",
    "\"\"\"\n",
    "def extract_articulations(cc: int, uni: int) -> pl.DataFrame:\n",
    "    # extract data from query & construct polars dataframe\n",
    "    articulations = pl.from_pandas(pd.DataFrame(get_query(cc, uni)))\n",
    "    \n",
    "    colname = \"articulation\"\n",
    "    if \"articulations\" in articulations.columns:\n",
    "        articulations = articulations.explode(\"articulations\")\n",
    "        colname = \"articulations\"\n",
    "    articulations_struct = articulations.get_column(colname).struct\n",
    "\n",
    "    articulations = pl.concat((\n",
    "        articulations_struct.field(\"course\").struct.field(\"courseIdentifierParentId\").rename(\"course_id\").to_frame(),\n",
    "        articulations_struct.field(\"series\").to_frame(),\n",
    "        articulations_struct.field(\"sendingArticulation\").to_frame()\n",
    "    ), how=\"horizontal\")\n",
    "    \n",
    "    \n",
    "    # transform into mapping of course id : relationship to course ids that articulate to it\n",
    "    articulations = (\n",
    "        articulations\n",
    "        \n",
    "        # extract courses from uni series objects and treat them as individual courses\n",
    "        # premise: A and B articulates to C and D => A and B articulates to C and A and B articulates D\n",
    "        .with_columns(pl.col(\"series\").struct.field(\"courses\"))\n",
    "        .explode(\"courses\")\n",
    "        \n",
    "        # extract sendingArticulation field (contains A and B) and id of C/D courses\n",
    "        .with_columns(\n",
    "            course_id=pl.coalesce(\n",
    "                \"course_id\",\n",
    "                pl.col(\"courses\").struct.field(\"courseIdentifierParentId\")\n",
    "            ),\n",
    "            items=(\n",
    "                pl.when(pl.col(\"sendingArticulation\").struct.field(\"items\").list.len() > 0)\n",
    "                .then(pl.col(\"sendingArticulation\").struct.field(\"items\"))\n",
    "                .otherwise(None)\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        # transform sendingArticulation to only keep course ids from whole course structs for C/D\n",
    "        .with_columns(\n",
    "            pl.col(\"items\").list.eval(\n",
    "                pl.struct([\n",
    "                    pl.element().struct.field(\"courseConjunction\").alias(\"conj\"),\n",
    "                    pl.element().struct.field(\"items\").list.eval(\n",
    "                        pl.element().struct.field(\"courseIdentifierParentId\")\n",
    "                    ).alias(\"ids\")\n",
    "                ]).struct.json_encode()  # uncomment to convert struct to json string\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # ensure AND groupings are grouped together by the proper group conjunction\n",
    "        # with OR as the default if articulation exists else null\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"items\").is_not_null())\n",
    "            .then(\n",
    "                    pl.struct([\n",
    "                    pl.when(\n",
    "                        pl.col(\"sendingArticulation\")\n",
    "                        .struct.field(\"courseGroupConjunctions\")\n",
    "                        .list.len() > 0\n",
    "                    )\n",
    "                    .then(\n",
    "                        pl.col(\"sendingArticulation\")\n",
    "                        .struct.field(\"courseGroupConjunctions\")\n",
    "                        .list.first()\n",
    "                        .struct.field(\"groupConjunction\")\n",
    "                    )\n",
    "                    .otherwise(pl.lit(\"Or\"))\n",
    "                    .alias(\"groupConj\"),\n",
    "                    \n",
    "                    pl.col(\"items\")\n",
    "                ])\n",
    "            )\n",
    "            .otherwise(None)\n",
    "        )\n",
    "        # drop intermediary columns\n",
    "        .drop([\"series\", \"courses\", \"sendingArticulation\", \"items\"])\n",
    "    ).rename({\"groupConj\": \"articulation\"})\n",
    "    \n",
    "    return articulations # return the result\n",
    "\n",
    "\n",
    "def drop_duplicates_by_term(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    order_terms = {\"W\": 0, \"S\": 1, \"Su\": 2, \"F\": 3}\n",
    "    # separate the term from the year\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"begin\").str.slice(-4, 4).cast(pl.Int32).alias(\"year\"),\n",
    "        pl.col(\"begin\").str.slice(0, pl.col(\"begin\").str.len_chars() - 4).alias(\"term\")\n",
    "    )\n",
    "    # the higher the value, the newer the agreement\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"year\") * 10 + pl.col(\"term\").replace_strict(order_terms)).alias(\"combined\")\n",
    "    )  \n",
    "    # remove all but the newest instance of a course\n",
    "    df = df.sort(\"combined\", descending=True).unique(\"course_id\", keep=\"first\")\n",
    "    \n",
    "    return df.drop([\"begin\", \"term\", \"year\", \"combined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (115, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>course_id</th><th>articulation</th></tr><tr><td>i64</td><td>struct[2]</td></tr></thead><tbody><tr><td>355071</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[203594]}&quot;]}</td></tr><tr><td>259939</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[214753,164338]}&quot;]}</td></tr><tr><td>298987</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[350297]}&quot;]}</td></tr><tr><td>305742</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[41537,211787]}&quot;]}</td></tr><tr><td>294493</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[207521]}&quot;]}</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>257983</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[302233,298570]}&quot;]}</td></tr><tr><td>259948</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[339988]}&quot;, &quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[267304]}&quot;]}</td></tr><tr><td>289377</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[366063,366074]}&quot;]}</td></tr><tr><td>298037</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[165947]}&quot;]}</td></tr><tr><td>289409</td><td>{&quot;Or&quot;,[&quot;{&quot;conj&quot;:&quot;And&quot;,&quot;ids&quot;:[280860]}&quot;]}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (115, 2)\n",
       "┌───────────┬─────────────────────────────────┐\n",
       "│ course_id ┆ articulation                    │\n",
       "│ ---       ┆ ---                             │\n",
       "│ i64       ┆ struct[2]                       │\n",
       "╞═══════════╪═════════════════════════════════╡\n",
       "│ 355071    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[2… │\n",
       "│ 259939    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[2… │\n",
       "│ 298987    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[3… │\n",
       "│ 305742    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[4… │\n",
       "│ 294493    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[2… │\n",
       "│ …         ┆ …                               │\n",
       "│ 257983    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[3… │\n",
       "│ 259948    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[3… │\n",
       "│ 289377    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[3… │\n",
       "│ 298037    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[1… │\n",
       "│ 289409    ┆ {\"Or\",[\"{\"conj\":\"And\",\"ids\":[2… │\n",
       "└───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_articulations(45, 7).unique().filter(pl.col(\"articulation\").is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a test run of a full course glossary\n",
    "\"\"\"\n",
    "\n",
    "def create_full_glossary():\n",
    "    with open(\"./data/institutions_cc.json\", \"r\") as cc_fp, open(\"./data/institutions_state.json\", \"r\") as uni_fp:\n",
    "        cc_ids = json.load(cc_fp).keys()\n",
    "        uni_ids = json.load(uni_fp).keys()\n",
    "    \n",
    "    glossary = []\n",
    "    cc_count = 0\n",
    "    for uni_id in uni_ids:\n",
    "        batch = []\n",
    "        for cc_id in cc_ids:\n",
    "            try:\n",
    "                batch.append(create_course_glossary(cc=cc_id,uni=uni_id))\n",
    "                cc_count += 1\n",
    "            except FileNotFoundError:  # no query exists, no query was scraped\n",
    "                continue\n",
    "        if batch:\n",
    "            glossary.extend(batch)\n",
    "        print(\"created\", cc_count, \"dfs for uni ID:\", uni_id)\n",
    "        cc_count = 0\n",
    "    print(\"glossary list constructed\")\n",
    "    return pl.concat(glossary).unique()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Notes: getting errors for the following cc:uni combos\n",
    "KeyError 'articulations': 51:1, 55:26, 124:26\n",
    "TypeError: str + NoneType unsupported: 97:21, 51:50\n",
    "\n",
    "Checking files...\n",
    "51:1 -> AllMajors file, diff schema, no by dept split\n",
    "\n",
    "AllPrefixes Schema: \n",
    "results\n",
    "-> articulations\n",
    "    -> list of depts\n",
    "        -> name, list of articulations for dept\n",
    "            -> course objects\n",
    "            \n",
    "AllMajors Schema:\n",
    "results\n",
    "-> articulations\n",
    "    -> list of articulations\n",
    "        -> templateCellId, articulation, \n",
    "\"\"\"\n",
    "\"\"\n",
    "# glossary = create_full_glossary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created 115 dfs for uni ID: 1\n",
      "created 115 dfs for uni ID: 7\n",
      "created 115 dfs for uni ID: 11\n",
      "created 115 dfs for uni ID: 12\n",
      "created 115 dfs for uni ID: 21\n",
      "created 0 dfs for uni ID: 23\n",
      "created 115 dfs for uni ID: 24\n",
      "created 11 dfs for uni ID: 26\n",
      "created 90 dfs for uni ID: 29\n",
      "created 115 dfs for uni ID: 39\n",
      "created 115 dfs for uni ID: 42\n",
      "created 115 dfs for uni ID: 46\n",
      "created 115 dfs for uni ID: 50\n",
      "created 115 dfs for uni ID: 60\n",
      "created 115 dfs for uni ID: 75\n",
      "created 115 dfs for uni ID: 76\n",
      "created 115 dfs for uni ID: 79\n",
      "created 115 dfs for uni ID: 81\n",
      "created 48 dfs for uni ID: 85\n",
      "created 115 dfs for uni ID: 88\n",
      "created 114 dfs for uni ID: 89\n",
      "created 115 dfs for uni ID: 98\n",
      "created 0 dfs for uni ID: 115\n",
      "created 115 dfs for uni ID: 116\n",
      "created 115 dfs for uni ID: 117\n",
      "created 115 dfs for uni ID: 120\n",
      "created 115 dfs for uni ID: 128\n",
      "created 115 dfs for uni ID: 129\n",
      "created 115 dfs for uni ID: 132\n",
      "created 113 dfs for uni ID: 141\n",
      "created 115 dfs for uni ID: 143\n",
      "created 115 dfs for uni ID: 144\n",
      "glossary list constructed\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: course_glossary.course_id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntegrityError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     27\u001b[39m     uni_ids = json.load(uni_fp).keys()\n\u001b[32m     29\u001b[39m glossary_df: pl.DataFrame = create_full_glossary().unique()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglossary_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglossary_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcourse_glossary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mappend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CACourses/pyvenv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CACourses/pyvenv/lib/python3.12/site-packages/pandas/core/generic.py:3087\u001b[39m, in \u001b[36mNDFrame.to_sql\u001b[39m\u001b[34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[39m\n\u001b[32m   2889\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2890\u001b[39m \u001b[33;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[32m   2891\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3083\u001b[39m \u001b[33;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[32m   3084\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   3085\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[32m-> \u001b[39m\u001b[32m3087\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3088\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CACourses/pyvenv/lib/python3.12/site-packages/pandas/io/sql.py:842\u001b[39m, in \u001b[36mto_sql\u001b[39m\u001b[34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    838\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument should be either a Series or a DataFrame\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m     )\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema=schema, need_transaction=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CACourses/pyvenv/lib/python3.12/site-packages/pandas/io/sql.py:2851\u001b[39m, in \u001b[36mSQLiteDatabase.to_sql\u001b[39m\u001b[34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m table = SQLiteTable(\n\u001b[32m   2842\u001b[39m     name,\n\u001b[32m   2843\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2848\u001b[39m     dtype=dtype,\n\u001b[32m   2849\u001b[39m )\n\u001b[32m   2850\u001b[39m table.create()\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CACourses/pyvenv/lib/python3.12/site-packages/pandas/io/sql.py:1119\u001b[39m, in \u001b[36mSQLTable.insert\u001b[39m\u001b[34m(self, chunksize, method)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1118\u001b[39m chunk_iter = \u001b[38;5;28mzip\u001b[39m(*(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m num_inserted = \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CACourses/pyvenv/lib/python3.12/site-packages/pandas/io/sql.py:2547\u001b[39m, in \u001b[36mSQLiteTable._execute_insert\u001b[39m\u001b[34m(self, conn, keys, data_iter)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_insert\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn, keys, data_iter) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   2546\u001b[39m     data_list = \u001b[38;5;28mlist\u001b[39m(data_iter)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minsert_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m conn.rowcount\n",
      "\u001b[31mIntegrityError\u001b[39m: UNIQUE constraint failed: course_glossary.course_id"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dump glossary with SQLite3\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3 as sql3\n",
    "\n",
    "with sql3.connect(\"./test.db\") as conn:\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # create table\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS course_glossary;\")\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS course_glossary (\n",
    "            course_id INTEGER PRIMARY KEY,\n",
    "            inst_id INTEGER,\n",
    "            course_code TEXT,\n",
    "            course_name TEXT,\n",
    "            min_units REAL,\n",
    "            max_units REAL,\n",
    "            begin TEXT\n",
    "        );\n",
    "    \"\"\")\n",
    "    \n",
    "    with open(\"./data/institutions_cc.json\", \"r\") as cc_fp, open(\"./data/institutions_state.json\", \"r\") as uni_fp:\n",
    "        cc_ids = json.load(cc_fp).keys()\n",
    "        uni_ids = json.load(uni_fp).keys()\n",
    "           \n",
    "    glossary_df: pl.DataFrame = create_full_glossary().unique()\n",
    "    \n",
    "    pd.DataFrame(glossary_df, columns=glossary_df.columns).to_sql(\n",
    "        name=\"course_glossary\",\n",
    "        if_exists=\"append\",\n",
    "        con=conn,\n",
    "        index=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
