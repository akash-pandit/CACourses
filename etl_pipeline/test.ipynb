{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# typing\n",
    "from polars import DataType, Schema\n",
    "from polars._typing import PolarsDataType\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4bdaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECTDIR = Path(\"/home/akash/Main/projects/CACourses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df2d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_dtypes(dtype1: PolarsDataType, dtype2: PolarsDataType) -> PolarsDataType:\n",
    "    \"\"\"Recursively merges two Polars data types into a supertype.\"\"\"\n",
    "    # If types are the same, no merge needed\n",
    "    if dtype1 == dtype2:\n",
    "        return dtype1\n",
    "    \n",
    "    # Null type is superseded by any other type\n",
    "    if isinstance(dtype1, pl.Null):\n",
    "        return dtype2\n",
    "    if isinstance(dtype2, pl.Null):\n",
    "        return dtype1\n",
    "\n",
    "    # Recursively merge for List types\n",
    "    if isinstance(dtype1, pl.List) and isinstance(dtype2, pl.List):\n",
    "        merged_inner = _merge_dtypes(dtype1.inner, dtype2.inner)\n",
    "        return pl.List(merged_inner)\n",
    "\n",
    "    # Recursively merge for Struct types\n",
    "    if isinstance(dtype1, pl.Struct) and isinstance(dtype2, pl.Struct):\n",
    "        # Combine fields from both structs\n",
    "        merged_fields = dtype1.to_schema()\n",
    "        for field_name, field_dtype in dtype2.to_schema().items():\n",
    "            merged_fields[field_name] = _merge_dtypes(merged_fields[field_name], field_dtype) if field_name in merged_fields else field_dtype\n",
    "        return pl.Struct(merged_fields)\n",
    "\n",
    "    # For other types, use Polars' built-in supertype casting\n",
    "    try:\n",
    "        # Create dummy series and find the supertype upon concatenation\n",
    "        super_type = pl.concat(\n",
    "            [pl.Series([None], dtype=dtype1), pl.Series([None], dtype=dtype2)],\n",
    "            how=\"diagonal_relaxed\",\n",
    "        ).dtype\n",
    "        return super_type\n",
    "    except Exception:\n",
    "        # If Polars can't find a common supertype (e.g., Int64 and Struct), raise an error\n",
    "        raise TypeError(f\"Could not merge incompatible types: {dtype1} and {dtype2}\")\n",
    "\n",
    "\n",
    "def merge_schemas(schemas: list[pl.Schema]) -> pl.Schema:\n",
    "    \"\"\"\n",
    "    Merges a list of Polars schemas into a single, generalized schema.\n",
    "\n",
    "    Args:\n",
    "        schemas: A list of schema dictionaries (e.g., from `df.schema`).\n",
    "\n",
    "    Returns:\n",
    "        A single schema dictionary that covers all fields and types.\n",
    "    \"\"\"\n",
    "    if not schemas:\n",
    "        return pl.Schema()\n",
    "\n",
    "    # Start with the first schema as the base\n",
    "    merged_schema = dict(schemas[0])\n",
    "\n",
    "    # Iteratively merge the remaining schemas\n",
    "    for schema in schemas[1:]:\n",
    "        for field_name, field_dtype in schema.items():\n",
    "            if field_name in merged_schema:\n",
    "                # Field exists, merge the data types\n",
    "                existing_dtype = merged_schema[field_name]\n",
    "                merged_schema[field_name] = _merge_dtypes(existing_dtype, field_dtype)\n",
    "            else:\n",
    "                # New field, just add it to the schema\n",
    "                merged_schema[field_name] = field_dtype\n",
    "    \n",
    "    return Schema(merged_schema)\n",
    "\n",
    "\n",
    "def extract_articulations_optimized(fp: str | Path, schema: pl.Schema) -> pl.DataFrame:\n",
    "    path = Path(fp)\n",
    "    # Robust path parsing\n",
    "    # print(path.parts)\n",
    "    uni = int(path.parts[-2])\n",
    "    cc = int(path.parts[-1].split(\"to\")[0])\n",
    "\n",
    "    if \"prefixes\" in str(fp):\n",
    "        df = pl.read_json(fp, schema=schema).explode(\"articulations\")\n",
    "    else:\n",
    "        df = pl.read_json(fp, schema=schema).rename({\"articulation\": \"articulations\"})\n",
    "\n",
    "    return (\n",
    "        df.select(\n",
    "            # Use select for efficient, simultaneous column creation\n",
    "            pl.col(\"articulations\").struct.field(\"course\").struct.field(\"courseIdentifierParentId\").alias(\"course_id\"),\n",
    "            pl.col(\"articulations\").struct.field(\"series\"),\n",
    "            pl.col(\"articulations\").struct.field(\"sendingArticulation\")\n",
    "        )\n",
    "        .with_columns(pl.col(\"series\").struct.field(\"courses\"))\n",
    "        .explode(\"courses\")\n",
    "        .with_columns(\n",
    "            # This logic remains largely the same, but benefits from a cleaner starting point\n",
    "            course_id=pl.coalesce(\n",
    "                \"course_id\",\n",
    "                pl.col(\"courses\").struct.field(\"courseIdentifierParentId\")\n",
    "            ),\n",
    "            # The 'when' is necessary to convert empty lists to null for later dropping\n",
    "            items=pl.when(pl.col(\"sendingArticulation\").struct.field(\"items\").list.len() > 0)\n",
    "                 .then(pl.col(\"sendingArticulation\").struct.field(\"items\"))\n",
    "                 .otherwise(None),\n",
    "            cc=pl.lit(cc),\n",
    "            uni=pl.lit(uni)\n",
    "        )\n",
    "        .drop_nulls(subset=\"items\") # Single drop_nulls is sufficient for this column\n",
    "        .drop(\"series\", \"courses\")\n",
    "        .with_columns(\n",
    "            articulation=pl.col(\"items\").list.eval(\n",
    "                pl.struct(\n",
    "                    conj=(\n",
    "                        pl.col(\"sendingArticulation\")\n",
    "                        .struct.field(\"courseGroupConjunctions\")\n",
    "                        .list.first()\n",
    "                        .struct.field(\"groupConjunction\")\n",
    "                        .fill_null(\"Or\") # Much cleaner than when/then/otherwise\n",
    "                    ),\n",
    "                    items=pl.struct(\n",
    "                        conj=pl.element().struct.field(\"courseConjunction\"),\n",
    "                        items=pl.element().struct.field(\"items\").list.eval(\n",
    "                            pl.element().struct.field(\"courseIdentifierParentId\")\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        .drop(\"sendingArticulation\", \"items\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb860cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_list_prefix = [\n",
    "    pl.read_json(\n",
    "        source=fp,\n",
    "        infer_schema_length=None\n",
    "    ).schema \n",
    "    for fp \n",
    "    in PROJECTDIR.glob(\"data/*/*prefixes.json\")\n",
    "]\n",
    "schema_list_major  = [\n",
    "    pl.read_json(\n",
    "        source=fp,\n",
    "        infer_schema_length=None\n",
    "    ).schema \n",
    "    for fp\n",
    "    in PROJECTDIR.glob(\"data/*/*majors.json\")\n",
    "]\n",
    "\n",
    "schema_prefix = merge_schemas(schema_list_prefix)\n",
    "schema_major  = merge_schemas(schema_list_major)\n",
    "\n",
    "del schema_list_prefix, schema_list_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1c37a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes_agg = pl.concat([\n",
    "    extract_articulations_optimized(fp, schema_prefix) \n",
    "    for fp\n",
    "    in PROJECTDIR.glob(\"data/*/*-prefixes.json\")\n",
    "]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f3b33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_agg = pl.concat([\n",
    "    extract_articulations_optimized(fp, schema_major) \n",
    "    for fp \n",
    "    in PROJECTDIR.glob(\"data/*/*-majors.json\")\n",
    "]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5b210d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes_agg.get_column('articulation')\n",
    "\n",
    "test_frame = (\n",
    "    prefixes_agg\n",
    "    .filter(pl.col(\"articulation\").list.len() > 2)\n",
    "    # .get_column('articulation')\n",
    "    .top_k(by=pl.col(\"articulation\"), k=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6958019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>course_id</th><th>cc</th><th>uni</th><th>articulation</th><th>groupConj</th></tr><tr><td>i64</td><td>i32</td><td>i32</td><td>list[struct[2]]</td><td>str</td></tr></thead><tbody><tr><td>65915</td><td>121</td><td>98</td><td>[{&quot;Or&quot;,[386545]}, {&quot;And&quot;,[386546]}, {&quot;And&quot;,[386549]}]</td><td>&quot;Or&quot;</td></tr><tr><td>237149</td><td>135</td><td>98</td><td>[{&quot;Or&quot;,[385694]}, {&quot;And&quot;,[385695]}, {&quot;And&quot;,[385696]}]</td><td>&quot;Or&quot;</td></tr><tr><td>374012</td><td>110</td><td>85</td><td>[{&quot;Or&quot;,[383729]}, {&quot;And&quot;,[383728]}, … {&quot;And&quot;,[385834]}]</td><td>&quot;Or&quot;</td></tr><tr><td>261048</td><td>14</td><td>141</td><td>[{&quot;Or&quot;,[380882, 387926]}, {&quot;Or&quot;,[380845, 386929]}, {&quot;Or&quot;,[380851, 386929]}]</td><td>&quot;Or&quot;</td></tr><tr><td>110050</td><td>153</td><td>128</td><td>[{&quot;Or&quot;,[372214, 372203]}, {&quot;Or&quot;,[372053, 372213]}, {&quot;And&quot;,[371870]}]</td><td>&quot;And&quot;</td></tr><tr><td>372609</td><td>153</td><td>128</td><td>[{&quot;Or&quot;,[372214, 372203]}, {&quot;Or&quot;,[372053, 372213]}, {&quot;And&quot;,[371870]}]</td><td>&quot;And&quot;</td></tr><tr><td>235554</td><td>153</td><td>128</td><td>[{&quot;Or&quot;,[372214, 372203]}, {&quot;Or&quot;,[372053, 372213]}, {&quot;And&quot;,[371870]}]</td><td>&quot;And&quot;</td></tr><tr><td>227332</td><td>153</td><td>128</td><td>[{&quot;Or&quot;,[372214, 372203]}, {&quot;Or&quot;,[372053, 372213]}, {&quot;And&quot;,[371870]}]</td><td>&quot;And&quot;</td></tr><tr><td>263383</td><td>153</td><td>128</td><td>[{&quot;Or&quot;,[372214, 372203]}, {&quot;Or&quot;,[372053, 372213]}, {&quot;And&quot;,[371870]}]</td><td>&quot;And&quot;</td></tr><tr><td>372611</td><td>153</td><td>128</td><td>[{&quot;Or&quot;,[372214, 372203]}, {&quot;Or&quot;,[372053, 372213]}, {&quot;And&quot;,[371870]}]</td><td>&quot;And&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "┌───────────┬─────┬─────┬─────────────────────────────────┬───────────┐\n",
       "│ course_id ┆ cc  ┆ uni ┆ articulation                    ┆ groupConj │\n",
       "│ ---       ┆ --- ┆ --- ┆ ---                             ┆ ---       │\n",
       "│ i64       ┆ i32 ┆ i32 ┆ list[struct[2]]                 ┆ str       │\n",
       "╞═══════════╪═════╪═════╪═════════════════════════════════╪═══════════╡\n",
       "│ 65915     ┆ 121 ┆ 98  ┆ [{\"Or\",[386545]}, {\"And\",[3865… ┆ Or        │\n",
       "│ 237149    ┆ 135 ┆ 98  ┆ [{\"Or\",[385694]}, {\"And\",[3856… ┆ Or        │\n",
       "│ 374012    ┆ 110 ┆ 85  ┆ [{\"Or\",[383729]}, {\"And\",[3837… ┆ Or        │\n",
       "│ 261048    ┆ 14  ┆ 141 ┆ [{\"Or\",[380882, 387926]}, {\"Or… ┆ Or        │\n",
       "│ 110050    ┆ 153 ┆ 128 ┆ [{\"Or\",[372214, 372203]}, {\"Or… ┆ And       │\n",
       "│ 372609    ┆ 153 ┆ 128 ┆ [{\"Or\",[372214, 372203]}, {\"Or… ┆ And       │\n",
       "│ 235554    ┆ 153 ┆ 128 ┆ [{\"Or\",[372214, 372203]}, {\"Or… ┆ And       │\n",
       "│ 227332    ┆ 153 ┆ 128 ┆ [{\"Or\",[372214, 372203]}, {\"Or… ┆ And       │\n",
       "│ 263383    ┆ 153 ┆ 128 ┆ [{\"Or\",[372214, 372203]}, {\"Or… ┆ And       │\n",
       "│ 372611    ┆ 153 ┆ 128 ┆ [{\"Or\",[372214, 372203]}, {\"Or… ┆ And       │\n",
       "└───────────┴─────┴─────┴─────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dnf(item: int | dict[str, int | dict]) -> list[list[int]]:\n",
    "    if isinstance(item, int):\n",
    "        return [[item]]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
